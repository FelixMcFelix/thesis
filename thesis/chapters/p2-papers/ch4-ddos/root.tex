\chapter{DDoS Prevention by Multi-Agent Reinforcement Learning}\label{chap:ddos-rl}
?? Something to elaborate on versus paper: design of Ryu controller?

\glspl{acr:iat}

The work presented in this chapter considers how online \gls{acr:rl} can be used to defend networks from volumetric \gls{acr:ddos} attacks, and is based upon \citetitle{DBLP:journals/tnsm/SimpsonRP20}~\parencite{DBLP:journals/tnsm/SimpsonRP20}.
?? Then summarise contents from here...

% \section{Threat Model}
% \section{Agent Design}
% \subsection{Weaknesses in Prior Art}
% \subsection{Feature Spaces}
% \subsection{Reward Functions}
% \subsection{Action Spaces}
% \subsection{Systems and Threat Considerations}
% \section{System Design}
% \section{Modified Learning Algorithms}
% \section{Methodology}
% \subsection{Traffic Modelling}
% \subsection{Topologies and Testing Environments}
% \section{Evaluation}
% \subsection{Congestion-aware Traffic}
% \subsection{Congestion-unaware Traffic}
% \subsection{Increased Attack Volume}
% \subsection{Computational Cost}

\section{Introduction}
\input{chapters/p2-papers/ch4-ddos/introduction.tex}

\section{Background and Threat Model}
\input{chapters/p2-papers/ch4-ddos/bg-threat.tex}

\section{DDoS Mitigation with Per-flow Reinforcement Learning}\label{sec:ddos-mitigation-with-per-flow-reinforcement-learning}
\input{chapters/p2-papers/ch4-ddos/algo.tex}

\section{System Architecture}\label{sec:system-architecture}
\input{chapters/p2-papers/ch4-ddos/arch.tex}

\section{Rethinking the State Space}\label{sec:rethinking-the-state-space}
\input{chapters/p2-papers/ch4-ddos/state-space.tex}

\section{Traffic Modelling}\label{sec:a-new-normal}
\input{chapters/p2-papers/ch4-ddos/traffic-modelling.tex}

\section{Evaluation}\label{sec:evaluation}
\input{chapters/p2-papers/ch4-ddos/evaluation.tex}

\section{Results}\label{sec:the-results-of-doing-so}
\input{chapters/p2-papers/ch4-ddos/results.tex}

\section{Discussion}\label{sec:discussion}
\input{chapters/p2-papers/ch4-ddos/discussion.tex}

\section{Related Work}\label{sec:related-work}
\input{chapters/p2-papers/ch4-ddos/related.tex}

\section{Conclusions and Future Work}
Through this paper, we have discussed reinforcement learning and its relevance to network intrusion prevention.
We believe the potential to learn feedback loop-like control online and against non-stationarity makes it particularly suited to the problems endemic to the field.
We identified weaknesses in past work, recommending an RL agent which acts per flow, and have outlined the algorithmic and engineering choices needed to make its deployment feasible.
Supporting this, we've presented an in-depth examination of our feature space, offering quantitative and qualitative justification for our choices.
Our evaluation shows that our new agent designs considerably advance the state-of-the-art in RL-based DDoS prevention, with \emph{Guarded} agents showing the most promise for future evaluation.

The most direct improvements to be made lie in the correct protection of legitimate UDP traffic, which our agent designs have difficulty safeguarding.
Outside of this, there is scope to test these new techniques against link-flooding attacks in large-scale topologies using reward functions such as \cref{eqn:lfa-reward}.
Simulation is the most likely avenue for such evaluation.

%(rather than na\"{i}ve simulation, blind ML applications etc.) and choose well-considered pathways to solution. \emph{Call-to-action}?

%\section{Future Work}
%Airlift half of the ``conclusion'' and paste it in here, so that it can be a lot neater.
%?? Future Work? I.e., \emph{everything}: no one else is really looking at/interested in this specific kind of application of RL yet. \emph{Yet}.

%?? IDEA: try out average reward, TD($\lambda$) methods as future work...
%A natural research direction to enhance this work would be the combination of the classic function approximation techniques we make use of alongside the improved algorithms that the RL community has introduced in the past few years.
%Actor-critic methods, or algorithms based on eligibility traces are good candidates for investigation. 
The remaining weaknesses invite many improvements worth investigation.
%?? What might we do for a reward function in the absence of heuristic estimates and/or explicit a priori knowledge? I think a good candidate is the sum of up and down throughputs (normalised by capacity sum), so long as \emph{neither exceeds the link capacity}. We can extend the team-based formulations similarly. This, in theory, promotes traffic diversity since it's not like flooding-based DDoS attacks are going to submit meaningful work to a server. The intuition, I suppose, is that certain classes of flow will have a small footprint in one direction which causes a sizeable increase in the other! Alternatively, monitor the health of canary flows which cross the team boundary (i.e. only one in-out link).
A problem we raised (without a clear solution) was the design of reward functions which do not rely upon heuristic estimates or a priori knowledge of benign traffic content.
If true online learning is desired (i.e., coping with a non-stationary environment), then such reward functions are sorely needed.
While $\bload{\cdot}$ is likely to be a good candidate for many deployments, we believe that finding an effective metric derived from the individual statistics we suggested serves as an interesting research problem.

%?? Benefit of the more realistic emulation environment is that it is far closer in behaviour and architecture (i.e. viable) to a real SDN-enabled deployment, captures some dynamics which were otherwise hidden/lost by human ignorance. It also allows me to develop the system towards evolving traffic models where it is expected that RL should shine over and above standard ML techniques. THEN: Room to introduce/roll-in dynamic changepoint detection or adaptive exploration \cite{DBLP:conf/ki/Tokic10, DBLP:conf/ki/TokicP11, DBLP:conf/annpr/TokicP12}?
Given that one of the advantages of RL methods is the ability to handle non-stationary problems, it is important to propose and test sensible simulations or captures of evolving networks.
While it is known that DDoS attack strategies evolve in real time \cite{DBLP:conf/spw/KangGS16}, evaluation is difficult at present since no works detail what patterns such evolution might take.
Regardless, these scenarios present ideal circumstances to apply adaptive exploration \cite{DBLP:conf/annpr/TokicP12}, changepoint detection, or intelligent sampling methods to judge which flows are most worthy of consideration.
For estimating \emph{when} to explore, we believe that the intersection of signal processing and RL is as-yet unexplored.

%?? IDEA: Apply these techniques to programmable data planes etc. While it's pretty neat that what we have works assuming that ach router is a software (x86) switch running OVS, what might we need to consider when applying this to `real' switches? ``PDP can allow this to be added to real routers to make it efficient to keep \& process state in the manner we require, as well as enabling more adaptive deployment''. Cite P4, BPFabric, other work on PDPs?
%?? What concessions will we have to make in order to make per-flow processing more viable? Intelligent sampling/reanalysis of flows when needed (i.e. an external heuristic guiding method)? In SPIFFY's \cite{DBLP:conf/ndss/KangGS16} evaluation, we see clearly that it can take around \SI{2}{\second} for a flow to react fully to a rate increase---I think for the TCP step it may be wise to factor this in, too!
%?? More future work --- share knowledge between agents. ``Knowledge bases'' for this purpose? (see: Qianru).
Effective real-world deployment of RL-based defences cannot assume that switches in a network will support a custom version of OVS or other arbitrary software, introducing the question of whether agent training, execution and distribution may be possible when using \emph{programmable data planes} \cite{DBLP:conf/ancs/JouetP17}.
We also expect it will be fruitful to look into \emph{how} agents may share knowledge with one another.

%?? Security? I suspect that the very qualities that make inference difficult in IDS/IPS also increase the level of challenge an advanced threat must overcome.
%?? Might want to mention it in related work above, but the recent attention on adversarial examples/tricking models needs to be looked into for RL. Poisoning attacks relevant for online techniques: old bounds exist \textcite{DBLP:journals/jmlr/KloftL10}, new stuff concerns collaborative learners \cite{DBLP:conf/acsac/ShenTS16}, nothing for rl. Hot topic in deep networks \cite{DBLP:conf/eurosp/PapernotMJFCS16, DBLP:conf/eurosp/PapernotMSW18}, but naturally still relevant with even linear approximations or exact tabular case due to limits of the PAC assumption. There is now examination of evasion attacks wrt.\ RL \cite{DBLP:journals/corr/HuangPGDA17}!
%?? evasion attacks by \textcite{DBLP:conf/sp/Carlini017}---all of these are computed by way of a general stochastic optimiser, such as \emph{Adam} \cite{DBLP:journals/corr/KingmaB14}. possible to apply something similar to our learned model to assess its security? would the suggested states even be valid? (i.e. since they're monotonically increasing for the most part).
Although we believe that the security landscape for classical RL models is not \emph{identical} to that of neural-network based approaches (particularly with such noisy, volatile, and hard-to-control data), there is still immense value in determining the exact capabilities of a sufficiently powerful adversary as the risk of external control still exists.
In particular, we believe that poisoning attacks and evasion attacks merit close consideration.

%While this work still trails behind the performance of exact DDoS flow detection mechanisms, w
We hope it is clear that reinforcement learning holds promise and can inspire further innovation.
It allows us to offer distinct advantages above existing works, such as protocol-agnostic DDoS flow detection, flexible deployment, and automatically learned low-overhead decision-making---without requiring many of the 
network resources or capabilities that other techniques rely upon.
It's hoped that more research in this direction will open the door to works which \emph{respect the complexity of the network}; evolving topologies, natural change in traffic and protocol distributions, and the mutation of attacks.

