\chapter{Netronome NFP Architectural Details}
\label{adx:nfp-arch}

\glsxtrfull{acr:nfp} SmartNICs are many-core \glsxtrfull{acr:soc} \glspl{acr:nic} designed for high performance packet processing at up to \qtyrange{40}{100}{\giga\bit\per\second}.
In concert with other SmartNIC designs, \gls{acr:nfp} SmartNICs are designed to allow virtually arbitrary packet processing written in the \emph{MicroC} language.
This appendix goes into greater detail on these particular SmartNIC devices due to their key role in \cref{chap:in-net-rl,chap:seidr}---primarily because going into meaningful depth concerning device particulars in those chapters would dilute their clarity.
Specific quantities, particularly around memory sizes or core counts, refer to the Netronome Agilio LX \numproduct{1 x 40}GbE SmartNIC (containing the NFP-6480 chipset).

\section{Execution Model}
\paragraph{Core layout.}
The Netronome NFP-6480 offers \num{112} cores, or \glsxtrfullpl{acr:me}, on which arbitrary programs may be run.
Cores are clustered into physical groups, termed \emph{islands}, each containing 4 or 12 \glspl{acr:me}.
Each \gls{acr:me} runs a single code store and operates at \qty{1.2}{\giga\hertz}, and all 12-\gls{acr:me} islands are used by a default P4 pipeline.
%How many islands?
%Some islands specialised.
Generally speaking, \glspl{acr:me} are able to communicate with one another and access one another's memory resources or capabilities.
As remote accesses, requests, and atomic operations are typically mediated by a shared \glsxtrfull{acr:cpp} bus, the cost of doing so typically scales such that cross-island operations are more expensive than island-local.
Many islands co-host specific accelerator functions or I/O capabilities, such as the \gls{acr:mac} and \gls{acr:pcie} bus, a management ARM processor, local memories, and cryptography accelerator units.

\paragraph{Threading.}
Threads on each \gls{acr:me} are known as \emph{contexts}, which are a class of hardware threads.
Each \gls{acr:me} may choose at compile time to run either 4 or 8 contexts, which then equally divide the register file and LMEM among themselves.\sidenote{In some cases, per-context resource use may be too great to allow all threads to operate.}
As one code store is maintained per \gls{acr:me}, all of its child contexts run the same program code though may query the current context number to enable branching behaviour.
Contexts are cooperatively scheduled at run time, where context switches are triggered by signalled I/O operations (who must be awaited) or by voluntary yield hints inserted by the programmer.
Context switches are effectively zero cost: as the register file is divided among all threads, another thread may instantly progress when the active thread chooses to sleep.
Each core offers \num{15} separate signals which can be independently fired for each context, and a thread may await any or all of a bitset of signals before it may progress.
These signals may be fired by other \glspl{acr:me}, contexts, or by the memory units in response to a completed I/O operation.

\paragraph{Programming.}
\gls{acr:nfp} devices support a proprietary assembler language, and a variant of the C programming language termed \emph{MicroC}.
This constitutes C with some additions, including an explicit memory model tailored towards this device, signalling and signal datatypes, and agressive inlining capabilities.
P4 programs may be compiled to target the \gls{acr:nfp}, at which point they are compiled into a selection of MicroC programs installed across most available islands.
Accordingly, P4 \texttt{extern}s resolve to MicroC programs which are arbitrarily defined and included by the programmer.

\section{Memory}
\Cref{tab:nfp-adx-mem} outlines the primary memory regions available, organised in terms of memory cost (where all registers are equal).
As above, these register files are split among all contexts at compile time.
Xfer registers are not usable outside of their purpose as holding space for the source and destination for I/O operations (and are visible to other \glspl{acr:me} and memory units).
Next-neighbour registers allow very fast writes between adjacent \glspl{acr:me} in an island.
These allow \glspl{acr:me} to communicate in one of two orders: \emph{chain} (0$\rightarrow$1$\rightarrow\dots\rightarrow$6$\rightarrow$7), and alternate (0$\rightarrow$2$\rightarrow\dots\rightarrow$5$\rightarrow$7).
Note that this communication is unidirectional and does not form a cycle.
Additionally, this functionality may be disabled on a per-\gls{acr:me} basis to provide additional register space.

Memories outside of EMEM are small in line with the typical expectations surrounding resource-limited environments like \gls{acr:pdp} hardware.
While almost all per-island or shared memories may be accessed from remote islands, cross-island accesses are more expensive and are typically avoided.
\Textcite[p.~30]{langlet-ml-netronome} relates his own measurements of these costs, save for EMEM Cache which is allocated and accessed---to the best of my knowledge---entirely by the compiler.
My understanding is that these are primarily occupied by \gls{acr:cam}-accelerated lookups via the provided hashtable primitives.

\begin{table}
	\centering
	\caption[NFP memory hierarchy, locations, and sizes.]{\gls{acr:nfp} memory hierarchy, locations, and sizes.\label{tab:nfp-adx-mem}}
	\begin{tabular}{@{}cccc@{}}
		\toprule
		Memory Region & Location & Remote Access & Size \\
		\midrule
		Register (GPR) & Per-\gls{acr:me} & \xmark & \qty{2}{\kibi\byte} \\
		Register (Xfer) & Per-\gls{acr:me} & \cmark & \qty{1}{\kibi\byte} In, \qty{1}{\kibi\byte} Out \\
		Register (NN) & Per-\gls{acr:me} & \xmark & \qty{512}{\byte} \\
		LMEM & Per-\gls{acr:me} & \xmark & \qty{4}{\kibi\byte} \\
		CLS & Per-Island & \cmark & \qty{64}{\kibi\byte} \\
		CTM & Per-Island & \cmark & \qty{256}{\kibi\byte} \\
		IMEM & i28, i29 & \cmark & \qty{4}{\mebi\byte} \\
		EMEM Cache & i24, i25, i26 & \cmark& \qty{3}{\mebi\byte} \\
		EMEM & i24, i25 & \cmark & \qty{4}{\gibi\byte}, \qty{3.5}{\gibi\byte}\\
		\bottomrule
	\end{tabular}
\end{table}

